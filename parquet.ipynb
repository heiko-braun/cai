{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35b09311-c858-455e-a652-ae704fd7f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import LanceDB\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import lancedb\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c6cbdc-91d0-4726-8fe1-9c45347e0a17",
   "metadata": {},
   "source": [
    "## Source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a48b497-6cbe-4517-86e0-4d7678b611f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>path</th>\n",
       "      <th>language</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>camel</td>\n",
       "      <td>/Users/opiske/code/java/camel/components/camel...</td>\n",
       "      <td>java</td>\n",
       "      <td></td>\n",
       "      <td>\"Shows how to create a custom check that can d...</td>\n",
       "      <td>if (count.intValue() &lt;= 1) {\\n  LOG.info(\"Coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>camel</td>\n",
       "      <td>/Users/opiske/code/java/camel/components/camel...</td>\n",
       "      <td>java</td>\n",
       "      <td></td>\n",
       "      <td>\"Shows how to build a Camel route can pause a ...</td>\n",
       "      <td>return new RouteBuilder(){\\n  @Override public...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camel</td>\n",
       "      <td>/Users/opiske/code/java/camel/components/camel...</td>\n",
       "      <td>java</td>\n",
       "      <td></td>\n",
       "      <td>\"Shows to create an adapter that is run by Cam...</td>\n",
       "      <td>if (count.intValue() &lt;= 1) {\\n  return true;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>camel</td>\n",
       "      <td>/Users/opiske/code/java/camel/components/camel...</td>\n",
       "      <td>java</td>\n",
       "      <td></td>\n",
       "      <td>\"Shows to create a route that uses the resume ...</td>\n",
       "      <td>return new RouteBuilder(){\\n  @Override public...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  project                                               path language tags  \\\n",
       "0   camel  /Users/opiske/code/java/camel/components/camel...     java        \n",
       "1   camel  /Users/opiske/code/java/camel/components/camel...     java        \n",
       "2   camel  /Users/opiske/code/java/camel/components/camel...     java        \n",
       "3   camel  /Users/opiske/code/java/camel/components/camel...     java        \n",
       "\n",
       "                                         description  \\\n",
       "0  \"Shows how to create a custom check that can d...   \n",
       "1  \"Shows how to build a Camel route can pause a ...   \n",
       "2  \"Shows to create an adapter that is run by Cam...   \n",
       "3  \"Shows to create a route that uses the resume ...   \n",
       "\n",
       "                                              source  \n",
       "0  if (count.intValue() <= 1) {\\n  LOG.info(\"Coun...  \n",
       "1  return new RouteBuilder(){\\n  @Override public...  \n",
       "2  if (count.intValue() <= 1) {\\n  return true;\\n...  \n",
       "3  return new RouteBuilder(){\\n  @Override public...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "df = pd.read_parquet('./data/parquet/sources-camel-kafka.parquet', engine='pyarrow')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6083e0-cfc0-45a9-a618-ae2cc46916f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num docs:  4\n",
      "\"Shows how to create a custom check that can determine whether to pause or continue\"\n",
      "\"Shows how to build a Camel route can pause a Kafka consumer when using the circuit breaker pattern\"\n",
      "\"Shows to create an adapter that is run by Camel when the resume happens \"\n",
      "\"Shows to create a route that uses the resume API\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "loader = DataFrameLoader(df, page_content_column=\"source\")\n",
    "docs = loader.load()\n",
    "print(\"Num docs: \", len(docs))\n",
    "\n",
    "[print(d) for d in list(df[\"description\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9244c30-d063-423c-bdfc-12dab24e72d0",
   "metadata": {},
   "source": [
    "## Retriever setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7992b42-dead-43f6-b343-4341cc31bb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 6 splits\n",
      "<class 'langchain_community.vectorstores.lancedb.LanceDB'>\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(f\"Created {len(splits)} splits\")\n",
    "\n",
    "# Use `description` as lancedb.embedding and `page_content` as lancedb.text\n",
    "# this way the lookups will be performed against the description values, but still return the actual sources into the LLM context\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = lancedb.connect(\"/tmp/lancedb\")\n",
    "table = db.create_table(\n",
    "    \"camel\",\n",
    "    data=[\n",
    "        {\n",
    "            \"vector\": embeddings.embed_query(\"Hello World\"),\n",
    "            \"text\": \"Hello World\",\n",
    "            \"id\": \"1\",\n",
    "        }\n",
    "    ],\n",
    "    mode=\"overwrite\",\n",
    ")\n",
    "\n",
    "# manually create the store so we get the embeddings right\n",
    "lancedb_data = []\n",
    "for i,doc in enumerate(splits):\n",
    "    lancedb_data.append(\n",
    "        {\n",
    "            \"vector\": embeddings.embed_query(doc.metadata[\"description\"]),\n",
    "            \"text\": doc.page_content,\n",
    "            \"id\": i,\n",
    "        }\n",
    "    )\n",
    "table.add(lancedb_data)\n",
    "\n",
    "# create a vectorstore from the pre-populated table\n",
    "vectorstore = LanceDB(table,embeddings)\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the sources found in the parquet files.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Please provide end-to-end examples in Java when applicable.\n",
    "\n",
    "    Question: {question} \n",
    "\n",
    "    Context: {context} \n",
    "\n",
    "    Answer:\n",
    "\"\"\")\n",
    "print(type(vectorstore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d9517-1719-4074-b051-1c4b86be18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at how the retriever actually works\n",
    "matches = retriever.get_relevant_documents(\"How can I pause a Kafka consumer?\")\n",
    "[print(f\"{i}:\\n {m.page_content}\") for i,m in enumerate(matches)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edf0b78-37fd-4e73-93d6-f0a5e5352366",
   "metadata": {},
   "source": [
    "## The actual Q&A involving the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a824cbcd-ef5b-46c5-b533-ff5da4ff78d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Example Questions&Answers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Can you show me how to use the resume API?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I'm sorry, but the provided context does not contain information about the resume API. Therefore, I don't know how to use the resume API based on the given context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### How do I determine whether to pause or continue a route? Do you have an example?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To determine whether to pause or continue a route, you can use the count value to make a decision. If the count is less than or equal to 1, or if it's greater than or equal to a predefined number of simulated failures, then you can allow the processing to proceed. Otherwise, you should not proceed at the moment.\n",
       "\n",
       "Here's an example in Java using the given context:\n",
       "\n",
       "```java\n",
       "// Assuming count is defined and initialized somewhere\n",
       "int count = getCount();\n",
       "final int SIMULATED_FAILURES = 5; // Assuming a predefined number of simulated failures\n",
       "\n",
       "if (count <= 1) {\n",
       "  LOG.info(\"Count is 1, allowing processing to proceed\");\n",
       "  // Continue the route\n",
       "} else if (count >= SIMULATED_FAILURES) {\n",
       "  LOG.info(\"Count is {}, allowing processing to proceed because it's greater than retry count {}\", count, SIMULATED_FAILURES);\n",
       "  // Continue the route\n",
       "} else {\n",
       "  LOG.info(\"Cannot proceed at the moment ... count is {}\", count);\n",
       "  // Pause the route or take appropriate action\n",
       "}\n",
       "```\n",
       "\n",
       "In the given context, the decision to pause or continue the route is made within the `CircuitBreaker` configuration. The `onError` event handler starts a thread to simulate checking for downstream availability, which can be considered as pausing the route until the downstream is available again. The `onSuccess` event handler shuts down the executor service, allowing the processing to proceed.\n",
       "\n",
       "If you have a specific use case or a different context in mind, please provide more details for a more tailored example."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\", temperature=0)\n",
    "\n",
    "def format_docs(docs):    \n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "questions = [\n",
    "    \"Can you show me how to use the resume API?\",    \n",
    "    \"How do I determine whether to pause or continue a route? Do you have an example?\",        \n",
    "]\n",
    "\n",
    "from langchain.globals import set_debug\n",
    "set_debug(False)\n",
    "\n",
    "display(Markdown(\"### Example Questions&Answers\"))\n",
    "for i,q in enumerate(questions):\n",
    "    display(Markdown(\"#### \"+q))\n",
    "    result = rag_chain.invoke(q)    \n",
    "    display(Markdown(result))    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
