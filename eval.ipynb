{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.agent import agent_executor, agent_llm\n",
    "from core.CustomTools import fetch_and_rerank\n",
    "\n",
    "from langchain.agents.openai_functions_agent.agent_token_buffer_memory import (\n",
    "    AgentTokenBufferMemory,\n",
    ")\n",
    "\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "import regex as re\n",
    "import glob\n",
    "\n",
    "from core.ragas import RagasCallbackHandler\n",
    "\n",
    "# ---\n",
    "\n",
    "#agent_memory = AgentTokenBufferMemory(llm=agent_llm)\n",
    "callback_handler = RagasCallbackHandler()\n",
    "def query_agent(prompt):\n",
    "   response = agent_executor(\n",
    "            {\"input\": prompt, \"history\": []},                        \n",
    "            callbacks=[callback_handler],\n",
    "            include_run_info=True,\n",
    "        )\n",
    "   return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions: 3\n",
      "Grounded Truths: 3\n"
     ]
    }
   ],
   "source": [
    "# source data\n",
    "\n",
    "filenames = []\n",
    "for _file in glob.glob(\"ragas_data/*.txt\"):\n",
    "    filenames.append(_file)\n",
    "\n",
    "questions = []\n",
    "ground_truths = []\n",
    "\n",
    "DELIM = \"__###__\"\n",
    "for name in filenames:\n",
    "    file_content = None\n",
    "    with open(name) as f:                \n",
    "        file_content = f.read()\n",
    "\n",
    "    content = file_content.split(DELIM)\n",
    "    questions.append(content[0])\n",
    "    truths = []\n",
    "    truths.append(content[1])\n",
    "    ground_truths.append(truths)\n",
    "\n",
    "print(\"Questions:\", len(questions))\n",
    "print(\"Grounded Truths:\", len(ground_truths))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "starting tool ...  file idempotent\n",
      "Embedding ms:  0.32719993591308594\n",
      "0.812 :  _next_file-component.html.txt_26\n",
      "0.805 :  _next_file-component.html.txt_25\n",
      "0.794 :  _next_azure-files-component.html.txt_11\n",
      "0.788 :  _next_file-component.html.txt_14\n",
      "0.781 :  _eips_competing-consumers.html.txt_2\n",
      "ending tool ... \n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Input:  1\n",
      "Outputs:  1\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "starting tool ...  event aggregation in Apache Camel\n",
      "Embedding ms:  0.37224912643432617\n",
      "0.831 :  _faq_how-do-the-direct-event-seda-and-vm-endpoints-compare.html.txt\n",
      "0.829 :  _others_cloudevents.html.txt\n",
      "0.82 :  _eips_aggregate-eip.html.txt_10\n",
      "0.829 :  _next_timer-component.html.txt_3\n",
      "0.83 :  _eips_split-eip.html.txt_10\n",
      "ending tool ... \n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Input:  1\n",
      "Outputs:  1\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "starting tool ...  file splitting\n",
      "Embedding ms:  0.4099709987640381\n",
      "0.783 :  _next_hdfs-component.html.txt_7\n",
      "0.781 :  _eips_split-eip.html.txt_0\n",
      "0.772 :  _next_sftp-component.html.txt_7\n",
      "0.777 :  _next_file-component.html.txt_24\n",
      "0.768 :  _dataformats_univocityFixed-dataformat.html.txt_0\n",
      "ending tool ... \n",
      "starting tool ...  AWS S3\n",
      "ending tool ... \n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Input:  2\n",
      "Outputs:  2\n",
      "Answer len: 3\n",
      "Context len: 3\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "# Inference\n",
    "for query in questions:\n",
    "  \n",
    "  # retrieve an answer\n",
    "  response = query_agent(query)\n",
    "  answers.append(response[\"output\"])\n",
    "\n",
    "  inputs, outputs = callback_handler.clear_collected_outputs()\n",
    "  print(\"Input: \", len(inputs))\n",
    "  print(\"Outputs: \", len(outputs))\n",
    "\n",
    "  results = []  \n",
    "  [results.append(doc) for doc in outputs]          \n",
    "  contexts.append(results)  \n",
    "\n",
    "print(\"Answer len:\", len(contexts))\n",
    "print(\"Context len:\", len(contexts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:56<00:00, 56.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:25<00:00, 25.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.58s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is my route\\n\\n    from(\"sftp://userName:...</td>\n",
       "      <td>To avoid processing the same files in case of ...</td>\n",
       "      <td>[page_content='\"Using a file based idempotent ...</td>\n",
       "      <td>[\\nTo avoid processing the same files in case ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.770217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am having an issue while working on the requ...</td>\n",
       "      <td>To listen to the events generated by one route...</td>\n",
       "      <td>[page_content='\"Article source: https://rhaeto...</td>\n",
       "      <td>[\\nTo listen to the events of one route by ano...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.795870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I want to read a local file, create equally si...</td>\n",
       "      <td>To achieve the desired functionality of readin...</td>\n",
       "      <td>[page_content='\"String\\n\\n\\n\\nCamelFileNameCon...</td>\n",
       "      <td>[\\nTo achieve this, you can use Apache Camel t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.792767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  This is my route\\n\\n    from(\"sftp://userName:...   \n",
       "1  I am having an issue while working on the requ...   \n",
       "2  I want to read a local file, create equally si...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  To avoid processing the same files in case of ...   \n",
       "1  To listen to the events generated by one route...   \n",
       "2  To achieve the desired functionality of readin...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [page_content='\"Using a file based idempotent ...   \n",
       "1  [page_content='\"Article source: https://rhaeto...   \n",
       "2  [page_content='\"String\\n\\n\\n\\nCamelFileNameCon...   \n",
       "\n",
       "                                       ground_truths  context_precision  \\\n",
       "0  [\\nTo avoid processing the same files in case ...                0.0   \n",
       "1  [\\nTo listen to the events of one route by ano...                1.0   \n",
       "2  [\\nTo achieve this, you can use Apache Camel t...                1.0   \n",
       "\n",
       "   context_recall  faithfulness  answer_relevancy  \n",
       "0             1.0      0.666667          0.770217  \n",
       "1             1.0      0.400000          0.795870  \n",
       "2             NaN      0.200000          0.792767  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To dict\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "\n",
    "# Convert dict to dataset\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "result = evaluate(\n",
    "    dataset = dataset, \n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "    ],\n",
    ")\n",
    "\n",
    "df = result.to_pandas()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
